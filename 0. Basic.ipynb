{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-1.6739  0.7834  0.7146\n",
      " 0.7311  1.2642  0.4907\n",
      "-1.0195 -1.9199  1.8519\n",
      " 0.6640  0.2892 -2.1121\n",
      "-1.6668 -1.7949 -1.3759\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Generate a random 5x3 Matrix\n",
    "x = torch.randn(5,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# module = Linear(inputDimension,outputDimension)\n",
    "### Applies a linear transformation to the incoming data, i.e. //y= Wx+b//. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      " 0.3326  0.0637 -0.4364\n",
      " 0.5296 -0.3063 -0.0562\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "Parameter containing:\n",
      " 0.0803\n",
      "-0.1674\n",
      "[torch.FloatTensor of size 2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Generate a linear transformation from dim 3 to dim 2 with random parameters Weight & Bias\n",
    "linear = nn.Linear(3,2)\n",
    "print(linear.weight)\n",
    "print(linear.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-0.7384 -1.3340\n",
      " 0.1898 -0.1951\n",
      "-1.1894 -0.2233\n",
      " 1.2414  0.2145\n",
      " 0.0120 -0.4228\n",
      "[torch.FloatTensor of size 5x2]\n",
      "\n",
      "Linear (3 -> 2)\n"
     ]
    }
   ],
   "source": [
    "#Put data into linear transformation to get the result\n",
    "y = linear(Variable(x))\n",
    "print (y)\n",
    "print(linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Add to a network\n",
    "Linear= nn.Linear(10,5)  \n",
    "m = nn.Sequential()\n",
    "m.add_module(module=Linear,name='Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1  2\n",
      " 3  4\n",
      "[torch.LongTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Transfer np.array to torch Tensor\n",
    "a = np.array([[1,2],[3,4]])\n",
    "b = torch.from_numpy(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document : http://pytorch.org/docs/torchvision/transforms.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#In short, to transform the input data for later training\n",
    "transform = transforms.Compose([\n",
    "    transforms.Scale(40),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32),\n",
    "    transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "torch.Size([3, 32, 32])\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "#Download Data Set\n",
    "train_dataset = dsets.CIFAR10(root='./data/',\n",
    "                               train=True, \n",
    "                               transform=transform,\n",
    "                               download=True)\n",
    "\n",
    "image, label = train_dataset[0]\n",
    "print (image.size())\n",
    "print (label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader = data.DataLoader(dataset=train_dataset,\n",
    "                               batch_size=100, \n",
    "                               shuffle=True,\n",
    "                               num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# iteration start then queue and thread start\n",
    "data_iter = iter(train_loader)\n",
    "\n",
    "# mini-batch images and labels\n",
    "images, labels = data_iter.next()\n",
    "\n",
    "for images, labels in train_loader:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load custom dataset\n",
    "class CustomDataset(data.Dataset):\n",
    "    def __init__(self):\n",
    "        # TODO\n",
    "        # 1. Initialize file path or list of file names. \n",
    "        pass\n",
    "    def __getitem__(self, index):\n",
    "        # TODO\n",
    "        # 1. Read one data from file (e.g. using numpy.fromfile, PIL.Image.open).\n",
    "        # 2. Preprocess the data (e.g. torchvision.Transform).\n",
    "        # 3. Return a data pair (e.g. image and label).\n",
    "        pass\n",
    "    def __len__(self):\n",
    "        # You should change 0 to the total size of your dataset.\n",
    "        return 0 \n",
    "\n",
    "# Then, you can just use prebuilt torch's data loader. \n",
    "custom_dataset = CustomDataset()\n",
    "train_loader = torch.utils.data.DataLoader(dataset=custom_dataset,\n",
    "                                           batch_size=100, \n",
    "                                           shuffle=True,\n",
    "                                           num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Download & load pretrained models\n",
    "resnet = torchvision.models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100])\n"
     ]
    }
   ],
   "source": [
    "# If you want to finetune only top layer of the model.\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "# Replace top layer for finetuning.\n",
    "resnet.fc = nn.Linear(resnet.fc.in_features, 100)  # 100 is for example.\n",
    "\n",
    "# For test.\n",
    "images = Variable(torch.randn(10, 3, 256, 256))\n",
    "outputs = resnet(images)\n",
    "print (outputs.size())   # (10, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save and load the entire model.\n",
    "torch.save(resnet, 'model.pkl')\n",
    "model = torch.load('model.pkl')\n",
    "\n",
    "# Save and load only the model parameters(recommended).\n",
    "torch.save(resnet.state_dict(), 'params.pkl')\n",
    "resnet.load_state_dict(torch.load('params.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 3\n",
      "[torch.FloatTensor of size 1]\n",
      " Variable containing:\n",
      " 4\n",
      "[torch.FloatTensor of size 1]\n",
      " Variable containing:\n",
      " 20\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = Variable(torch.Tensor([3]), requires_grad=True)\n",
    "w = Variable(torch.Tensor([4]), requires_grad=True)\n",
    "b = Variable(torch.Tensor([20]), requires_grad=True)\n",
    "print(x,w,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y =  2*w * x + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 44\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y.backward()   #Partial Differentiate every parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 8\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 6\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)    \n",
    "print(w.grad)    \n",
    "print(b.grad)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: Variable containing:\n",
      "-0.1706 -1.9050  1.3719\n",
      "-0.2103  0.4423 -0.2773\n",
      "-0.3801 -0.8468  0.2802\n",
      "-1.0409 -1.5621  1.2274\n",
      "-0.0432 -0.7304 -1.4813\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n",
      "y: Variable containing:\n",
      "-0.7187 -0.2424\n",
      " 0.0461  0.1277\n",
      "-0.9749  0.2873\n",
      "-0.0317 -0.2266\n",
      " 0.2661 -0.8796\n",
      "[torch.FloatTensor of size 5x2]\n",
      "\n",
      "w:  Parameter containing:\n",
      " 0.4473  0.2759 -0.0281\n",
      "-0.3915  0.4829 -0.0940\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "b:  Parameter containing:\n",
      "1.00000e-02 *\n",
      "  1.7566\n",
      "  4.0828\n",
      "[torch.FloatTensor of size 2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create tensors.\n",
    "x = Variable(torch.randn(5, 3))\n",
    "y = Variable(torch.randn(5, 2))\n",
    "print('x:',x)\n",
    "print('y:',y)\n",
    "# Build a linear layer.\n",
    "linear = nn.Linear(3, 2)\n",
    "print ('w: ', linear.weight)\n",
    "print ('b: ', linear.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build Loss and Optimizer.\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(linear.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.26969239115715027\n"
     ]
    }
   ],
   "source": [
    "loss = criterion(pred, y)\n",
    "print('loss: ', loss.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dL/dw:  Variable containing:\n",
      " 0.1395  0.2037 -0.0313\n",
      " 0.0887  0.3324 -0.4969\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "dL/db:  Variable containing:\n",
      "-0.1251\n",
      "-0.0935\n",
      "[torch.FloatTensor of size 2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print ('dL/dw: ', linear.weight.grad) \n",
    "print ('dL/db: ', linear.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss after 1 step optimization:  0.2652277946472168\n"
     ]
    }
   ],
   "source": [
    "pred = linear(x)\n",
    "loss = criterion(pred, y)\n",
    "print('loss after 1 step optimization: ', loss.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
